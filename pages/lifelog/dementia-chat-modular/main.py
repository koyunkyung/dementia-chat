# -*- coding: utf-8 -*-
# ===== ì¹˜ë§¤ ì§„ë‹¨ ëŒ€í™” ì‹œìŠ¤í…œ (ìˆ˜ì •ë³¸, ëª¨ë“ˆí˜•) =====
# [FIX] ì¼ê¸°ì¥ ëŒ€í™” ì €ì¥ ê°•í™” + KST ê¸°ì¤€ ë‚ ì§œ ì±„ì  ì•ˆì •í™” + ììœ  ë§¥ë½ í† í”½ ë¼ë²¨ë§ + 'ë‹¤ë¥¸ ë‹¨ì–´' ì „í™˜ / 'ê·¸ë§Œ' ì¢…ë£Œ
# [ADD] ì „ì²´ ëŒ€í™” ë¡œê·¸ DataFrame ì¡°íšŒ ê¸°ëŠ¥ (CSV ë¶ˆí•„ìš”)

import os, json, time, random, re, csv
import numpy as np
from datetime import datetime, timedelta, date
from collections import deque
from pathlib import Path

# ëª¨ë“ˆ ë¶„ë¦¬ëœ ê³µìš© í•¨ìˆ˜
from model import ask_gpt, resolve_finetuned_model, load_few_shot_empathy

# -------------------- Optional deps: FAISS / SentenceTransformer --------------------
try:
    import faiss
except Exception:
    os.system("pip install -q faiss-cpu")
    import faiss

try:
    from sentence_transformers import SentenceTransformer
except Exception:
    os.system("pip install -q sentence_transformers")
    from sentence_transformers import SentenceTransformer

# [ADD] pandas (DataFrameë¡œ ëŒ€í™” ë¶ˆëŸ¬ì˜¤ê¸°ìš©)
try:
    import pandas as pd
except Exception:
    os.system("pip install -q pandas")
    import pandas as pd

# ===================== 0) CONFIG =====================
CONFIG_TODAY_OVERRIDE = None  # e.g., "2025-09-03"  â† í•„ìš” ì‹œë§Œ ì„¤ì •

# ===================== 1) Fine-tuned Job IDs =====================
DIALECT_FT_JOB_ID  = "ftjob-5OaW41C27QVbi2NkMRjWgJEh"
EMPATHY_FT_JOB_ID  = "ftjob-EQXVYCKS5YaoknI9njHKvFvT"

FINETUNED_DIALECT_MODEL = None
FINETUNED_EMPATHY_MODEL = None

# ===================== 2) Embedding / FAISS =====================
embedder = SentenceTransformer("jhgan/ko-sbert-nli")
dimension = 768
faiss_index = faiss.IndexFlatL2(dimension)

# ===================== 3) Memories / Globals =====================
conversation_memory_std = []  # í‘œì¤€ì–´
conversation_memory_raw = []  # ì›ë¬¸(ì‚¬íˆ¬ë¦¬)

fact_memory = []        # list[dict]
fact_embeddings = []    # list[np.ndarray]
fact_id_counter = 0

memory_score = 100
RECENT_CONSISTENCY_BIN = deque(maxlen=5)

# ë§¥ë½ í† í”½ ìƒíƒœ
CONTEXT_TOPIC_LABEL = None
CONTEXT_TOPIC_CONF  = 0.0

# Diary state
DIARY_MODE = False
diary_memory = []
diary_id_counter = 0

# [FIX] Diary control keywords
DIARY_NEXT_WORDS = ["ë‹¤ë¥¸ ë‹¨ì–´"]
DIARY_STOP_WORDS = ["ê·¸ë§Œ", "ì¼ê¸° ë", "ì¼ê¸° ì¢…ë£Œ", "ì¢…ë£Œ", "ëë‚¼ë˜", "ê·¸ë§Œí• ë˜"]

# [ADD] ===== ì „ì²´ ëŒ€í™” ë¡œê·¸ =====
conversation_log = []   # list[dict]: {idx, ts, role, topic, content_raw, content_std, meta}
_conv_idx = 0

def _ts(ts):
    try:
        return datetime.fromtimestamp(float(ts)).strftime("%Y-%m-%d %H:%M:%S")
    except Exception:
        return ""

def log_event(role: str,
              content_raw: str | None = None,
              content_std: str | None = None,
              topic: str | None = None,
              meta: dict | None = None,
              ts: float | None = None):
    """ëª¨ë“  ëŒ€í™” í„´ì„ ì¼ê´€ í¬ë§·ìœ¼ë¡œ ê¸°ë¡."""
    global _conv_idx
    if ts is None:
        ts = time.time()
    conversation_log.append({
        "idx": _conv_idx,
        "ts": ts,
        "ts_str": _ts(ts),
        "role": role,
        "topic": topic or "",
        "content_raw": content_raw or "",
        "content_std": content_std or (content_raw or ""),
        "meta": json.dumps(meta, ensure_ascii=False) if meta else ""
    })
    _conv_idx += 1

def conversation_log_dataframe() -> pd.DataFrame:
    """ì„¸ì…˜ ë‚´ ì „ì²´ ëŒ€í™” DataFrame ë°˜í™˜(ë©”ëª¨ë¦¬ ìƒ)."""
    if not conversation_log:
        return pd.DataFrame(columns=["idx","ts","ts_str","role","topic","content_raw","content_std","meta"])
    df = pd.DataFrame(conversation_log)
    return df.sort_values("idx", ignore_index=True)

get_conversation_log_df = conversation_log_dataframe

# ===================== 4) Topic Pool (ë°±ì—…) =====================
BACKUP_MACRO_TOPICS = [
    "ê°€ì¡±ëª¨ì„","ê²½ë¡œë‹¹","ë³µì§€ê´€","í•™ì°½ì‹œì ˆ","ì¡¸ì—…ì‹","í™˜ê°‘","ì¹ ìˆœ","ëª…ì ˆ","ì„¤ë‚ ","ì¶”ì„",
    "ì‹œì¥","ê·¹ì¥","ì†ì£¼","ê±´ê°•ê²€ì§„","ë³‘ì›","ì•½êµ­","ì‹¤ë²„êµì‹¤",
    "êµíšŒ","ì„±ë‹¹","ì ˆ","ë´‰ì‚¬","ë™í˜¸íšŒ","ì‚°ì±…","ê³µì›","ë“±ì‚°","ë°”ë‹¤","ê°•ë³€",
    "ë²„ìŠ¤","ì§€í•˜ì² ","ì²­ì†Œ","ì§‘ì •ë¦¬","í¸ì§€","ì„ ë¬¼","ë‚ ì”¨","ë¹„","ëˆˆ","íšŒìƒ"
]

# ===================== 5) Utilities =====================
TIME_WORDS = ["ì˜¤ëŠ˜","ì–´ì œ","ë‚´ì¼","ì§€ê¸ˆ","ë°©ê¸ˆ","ì €ë…","ì•„ì¹¨","ì ì‹¬",
              "ì›”ìš”ì¼","í™”ìš”ì¼","ìˆ˜ìš”ì¼","ëª©ìš”ì¼","ê¸ˆìš”ì¼","í† ìš”ì¼","ì¼ìš”ì¼",
              "ì´ë²ˆ ì£¼","ì§€ë‚œ ì£¼","ë‹¤ìŒ ì£¼","ì´ë²ˆ ë‹¬","ì§€ë‚œ ë‹¬","ë‹¤ìŒ ë‹¬"]

def calc_specificity_score(text: str) -> float:
    if not text: return 0.0
    tokens = text.split()
    n = max(1, len(tokens))
    digits = sum(ch.isdigit() for ch in text)
    has_time = any(w in text for w in TIME_WORDS) or bool(re.search(r"\d{1,2}\s*ì›”\s*\d{1,2}\s*ì¼|\d{4}[-/.]\d{1,2}[-/.]\d{1,2}", text))
    named_like = sum(text.count(s) for s in ["ë‹˜","ì”¨","ì„ ìƒ","êµìˆ˜","ê³¼ì¥","íŒ€ì¥","ë°•ì‚¬","êµ°","ì–‘"])
    score = (0.3 * (1 if has_time else 0) +
             0.3 * min(1.0, digits/4) +
             0.2 * min(1.0, named_like/2) +
             0.2 * min(1.0, n/12))
    return max(0.0, min(1.0, score))

# ===================== 6) GPT Few-shot =====================
few_shot_empathy = load_few_shot_empathy()

# ===================== 7) Dialect â†’ Standard =====================
_DIALECT_SYSTEM_PROMPT = (
    "ë„ˆëŠ” í•œêµ­ì–´ ì‚¬íˆ¬ë¦¬ë¥¼ í•œêµ­ì–´ í‘œì¤€ì–´(ì¡´ëŒ“ë§)ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë°”ê¾¸ëŠ” ë„ìš°ë¯¸ì•¼. "
    "ì…ë ¥ ë¬¸ì¥ì´ ì‚¬íˆ¬ë¦¬ì¸ì§€ ê°ì§€í•˜ê³ , í‘œì¤€ì–´ë¡œ ë§¤ë„ëŸ½ê²Œ ë³€í™˜í•´. "
    "ì¡´ëŒ“ë§ë¡œ ë°”ê¾¸ë˜ ì˜ë¯¸ë¥¼ ë°”ê¾¸ì§€ ë§ê³ , ì¶œë ¥ì€ JSONìœ¼ë¡œë§Œ í•´."
)
_DIALECT_JSON_SCHEMA = """
ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µí•´:
{
  "standard": "í‘œì¤€ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë°”ê¾¼ ë¬¸ì¥",
  "is_dialect": true,
  "confidence": 0.0
}
"""
_DIALECT_MARKERS = ["ë°ì´","ì¹´ì´","ì•„ì´ê°€","ì•„ì…ë‹ˆêº¼","í•˜ê»˜","ì¿ ë‹¤","ë¨¸ì‹œ","ì¹´ë…¸","ì¹´ë”ë¼","í•˜ë¯„","ê·¸ë¼ë¯„",
                    "í–ˆì‹¬ë”","í–ˆë°ì´","í•˜ì´ì†Œ","í•˜ì…ë‹ˆë”","ë¬´í–ˆë…¸","ë§ˆ","ì˜ˆ","ê·¸ì¹´ì´","ê³ ë§ˆ","ê·¸ë¼ì œ"]

def _looks_like_dialect(s: str) -> bool:
    s = s or ""
    return any(tok in s for tok in _DIALECT_MARKERS)

def _safe_json_loads(raw: str, fallback: dict | None = None) -> dict | None:
    if not raw: return fallback
    try:
        return json.loads(raw)
    except Exception:
        pass
    if "{" in raw and "}" in raw:
        try:
            start, end = raw.index("{"), raw.rindex("}")+1
            return json.loads(raw[start:end])
        except Exception:
            return fallback
    return fallback

def normalize_user_utterance(user_text: str) -> dict:
    global FINETUNED_DIALECT_MODEL
    if FINETUNED_DIALECT_MODEL is None:
        FINETUNED_DIALECT_MODEL = resolve_finetuned_model(DIALECT_FT_JOB_ID)

    model_to_use = FINETUNED_DIALECT_MODEL or "gpt-4o-mini"
    prompt = f"{_DIALECT_SYSTEM_PROMPT}\n\nì…ë ¥:\n\"\"\"\n{user_text}\n\"\"\"\n\n{_DIALECT_JSON_SCHEMA}"
    raw = ask_gpt(prompt, model=model_to_use, temperature=0.0, max_tokens=200,
                  response_format={"type":"json_object"})
    data = _safe_json_loads(raw, fallback={})
    standard = (data.get("standard") or "").strip()
    is_dialect = bool(data.get("is_dialect", False))
    conf = float(data.get("confidence", 0.0) or 0.0)

    need_retry = (not standard) or ("ë„ˆëŠ” í•œêµ­ì–´ ì‚¬íˆ¬ë¦¬ë¥¼" in standard) or _looks_like_dialect(standard)
    if need_retry:
        raw2 = ask_gpt(prompt, model="gpt-4o-mini", temperature=0.0, max_tokens=200,
                       response_format={"type":"json_object"})
        data2 = _safe_json_loads(raw2, fallback={})
        standard2 = (data2.get("standard") or "").strip()
        if standard2 and "ë„ˆëŠ” í•œêµ­ì–´ ì‚¬íˆ¬ë¦¬ë¥¼" not in standard2 and not _looks_like_dialect(standard2):
            standard = standard2
            is_dialect = bool(data2.get("is_dialect", is_dialect))
            conf = float(data2.get("confidence", conf) or conf)

    if not standard or _looks_like_dialect(standard):
        minimalist_prompt = (
            "ë‹¤ìŒ ë¬¸ì¥ì„ í•œêµ­ì–´ í‘œì¤€ì–´(ì¡´ëŒ“ë§)ë¡œ í•œ ë¬¸ì¥ìœ¼ë¡œë§Œ ë°”ê¿”ì¤˜. "
            "JSON ì—†ì´ ê²°ê³¼ ë¬¸ì¥ë§Œ ì¶œë ¥í•´.\n\n"
            f"ë¬¸ì¥: {user_text}"
        )
        std3 = ask_gpt(minimalist_prompt, model="gpt-4o-mini", temperature=0.0, max_tokens=120,
                       response_format={"type":"text"})
        if std3:
            standard = std3.strip()

    if not standard:
        standard = user_text

    return {
        "standard": standard,
        "is_dialect": is_dialect,
        "confidence": max(0.0, min(1.0, conf)),
        "raw": user_text
    }

# ===================== 8) ë§¥ë½ í† í”½ ë¼ë²¨ë§ =====================
def _window_text(history_std: list[str], current_std: str, k:int=6) -> str:
    tail = " ".join(history_std[-k:])
    return (tail + " " + (current_std or "")).strip()

def infer_context_topic_label(history_std: list[str], current_std: str) -> tuple[str, float]:
    ctx = _window_text(history_std, current_std, k=6)
    prompt = (
        "ë‹¤ìŒ í•œêµ­ì–´ ëŒ€í™” ë§¥ë½ì˜ ì „ë°˜ ì£¼ì œë¥¼ 1~3ì–´ì ˆì˜ ì¼ë°˜ëª…ì‚¬/ì§§ì€ êµ¬ë¡œ ìš”ì•½í•˜ì„¸ìš”.\n"
        "ì„¸ë¶€ì–´/í¬ê·€ì–´ ê¸ˆì§€, ìƒˆ ì •ë³´ ì°½ì‘ ê¸ˆì§€.\n"
        "JSONìœ¼ë¡œë§Œ ë‹µ: {\"label\":\"...\",\"confidence\":0.0}\n\n"
        f"[ëŒ€í™” ë§¥ë½]\n{ctx}\n"
    )
    raw = ask_gpt(prompt, model="gpt-4o-mini", temperature=0.0, max_tokens=120,
                  response_format={"type":"json_object"})
    try:
        data = json.loads(raw)
        label = (data.get("label") or "").strip() or "ì¼ìƒ"
        conf = float(data.get("confidence", 0.0) or 0.0)
        if label in ["ì´ì•¼ê¸°","ëŒ€í™”","ì¼ìƒ ì´ì•¼ê¸°","ì†Œì†Œí•œ ëŒ€í™”"]:
            label, conf = "ì¼ìƒ", min(conf, 0.55)
        if len(label) > 20:
            label = label[:20]
        return label, conf
    except Exception:
        return "ì¼ìƒ", 0.0

def smooth_context_topic(new_label: str, new_conf: float,
                         prev_label: str | None, prev_conf: float,
                         min_change_conf: float = 0.60,
                         drift_guard: float = 0.15) -> tuple[str, float, bool]:
    if not prev_label:
        return new_label, new_conf, True
    if new_label == prev_label:
        fused = max(new_conf, (new_conf + prev_conf) / 2)
        return prev_label, fused, False
    if (new_conf >= min_change_conf) and ((new_conf - prev_conf) >= drift_guard):
        return new_label, new_conf, True
    return prev_label, prev_conf, False

# ===================== 9) Fact Extract / Store / Consistency =====================
def extract_claims_from_utterance(user_input_std: str, recent_history_std: list[str], original_raw: str, nrm_meta: dict):
    global fact_id_counter
    formatted_history = []
    for i, msg in enumerate(recent_history_std[-6:]):
        role = "ì‚¬ìš©ì(í‘œì¤€ì–´)" if i % 2 == 0 else "ì‹œìŠ¤í…œ"
        formatted_history.append(f"{role}: {msg}")
    recent_history_str = "\n".join(formatted_history)
    prompt = f"""
ìµœê·¼ ëŒ€í™” ê¸°ë¡ (ì°¸ê³ ìš©, í‘œì¤€ì–´ ê¸°ì¤€):
{recent_history_str}

ë‹¤ìŒ **ì‚¬ìš©ì ë°œí™”(í‘œì¤€ì–´)**ì—ì„œ **í•µì‹¬ì ì¸ ì‚¬ì‹¤(Claim)**ë§Œ ì¶”ì¶œí•˜ì—¬ JSON ë°°ì—´ í˜•íƒœë¡œ ë°˜í™˜í•´ ì£¼ì„¸ìš”.
ì˜ê²¬/ê°íƒ„/ì§ˆë¬¸/ì¼ë°˜ ì¸ì‚¬/ì¶”ì¸¡/ì¤‘ìš”ì¹˜ ì•Šì€ ë§ì€ ì œì™¸.
í•­ìƒ **ë°°ì—´**ë§Œ ë°˜í™˜. ì—†ìœ¼ë©´ [].

ê° ì‚¬ì‹¤ JSON í˜•ì‹:
{{
  "claim_text": "...",
  "entities": ["..."],
  "type": "ê°œì¸ì •ë³´|ì¼ìƒí™œë™|ê°ì •|ì‚¬ê±´|ê³„íš|...",
  "summary": "...",
  "time_reference": "ì–´ì œ|ì§€ë‚œì£¼|ì˜¤ëŠ˜|ë‚´ì¼|í˜„ì¬",
  "relative_offset_days": -1|0|1|null
}}

ì‚¬ìš©ì ë°œí™”(í‘œì¤€ì–´): "{user_input_std}"
"""
    json_str = ask_gpt(prompt, model="gpt-4o", temperature=0.2,
                       response_format={"type":"json_object"})
    try:
        claims_data = json.loads(json_str)
        if isinstance(claims_data, dict) and claims_data:
            claims_data = [claims_data] if 'claim_text' in claims_data else []
        elif not isinstance(claims_data, list):
            return []
        extracted = []
        for c in claims_data:
            ct = c.get("claim_text")
            if not ct: continue
            rod = c.get("relative_offset_days")
            if isinstance(rod, str) and rod.lower() == "null":
                rod = None
            extracted.append({
                "id": f"fact_{fact_id_counter}",
                "claim_text": ct,
                "entities": c.get("entities", []),
                "type": c.get("type","ë¯¸ë¶„ë¥˜"),
                "summary": c.get("summary", ct),
                "time_reference": c.get("time_reference","í˜„ì¬"),
                "relative_offset_days": rod,
                "original_utterance_raw": original_raw,
                "original_utterance_std": user_input_std,
                "was_dialect_normalized": bool(nrm_meta.get("is_dialect", False)),
                "dialect_confidence": float(nrm_meta.get("confidence", 0.0))
            })
            fact_id_counter += 1
        return extracted
    except Exception:
        return []

def store_extracted_facts(extracted_facts):
    for fact in extracted_facts:
        fact_ts = time.time()
        rod = fact.get("relative_offset_days")
        if isinstance(rod, (int,float)):
            fact_ts = (datetime.fromtimestamp(time.time()) + timedelta(days=rod)).timestamp()
        fact["timestamp"] = fact_ts
        fact_memory.append(fact)
        emb = embedder.encode([fact["claim_text"]])[0].astype("float32")
        fact_embeddings.append(emb)
        faiss_index.add(np.array([emb]))
    print(f"ğŸ’¾ {len(extracted_facts)}ê°œì˜ ì‚¬ì‹¤ ì €ì¥ë¨.")

def find_related_old_facts(new_claim_embedding, top_k=5):
    if not fact_embeddings: return []
    distances, indices = faiss_index.search(np.array([new_claim_embedding]).astype("float32"),
                                            min(top_k, len(fact_embeddings)))
    return [fact_memory[i] for i in indices[0] if i != -1]

def fact_tracking_agent(new_fact, related_old_facts):
    related = "\n".join([
        f"- ID:{f['id']}, ì‚¬ì‹¤:{f['claim_text']}, (í‘œì¤€ì–´ë°œí™”:'{f.get('original_utterance_std','')}', ì‹œê°„:{datetime.fromtimestamp(f['timestamp']).strftime('%Y-%m-%d %H:%M:%S')})"
        for f in related_old_facts
    ]) or "ì—†ìŒ."
    prompt = f"""
ìƒˆë¡œìš´ ì‚¬ìš©ì ë°œí™”ì—ì„œ ì¶”ì¶œëœ ì‚¬ì‹¤:
- ID:{new_fact['id']}, ì‚¬ì‹¤:"{new_fact['claim_text']}", (í‘œì¤€ì–´ë°œí™”:'{new_fact.get('original_utterance_std','')}', ì‹œê°„:{datetime.fromtimestamp(new_fact['timestamp']).strftime('%Y-%m-%d %H:%M:%S')})

ê´€ë ¨ ê¸°ì¡´ ì‚¬ì‹¤ë“¤:
{related}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ê´€ê³„ë¥¼ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¡œ JSONìœ¼ë¡œë§Œ ë°˜í™˜:
{{ "decision": "CONSISTENT|UPDATE|CONTRADICTION|NEW" }}
"""
    raw = ask_gpt(prompt, model="gpt-4o", temperature=0.2, max_tokens=200,
                  response_format={"type":"json_object"})
    try:
        data = json.loads(raw)
        if "decision" in data:
            return data
    except Exception:
        pass
    return {"decision":"ERROR"}

def check_memory_consistency(user_input_std: str, user_input_raw: str, nrm_meta: dict):
    global memory_score, CONTEXT_TOPIC_LABEL, CONTEXT_TOPIC_CONF, FINETUNED_EMPATHY_MODEL

    # ë§¥ë½ í† í”½ ì¶”ì • + ìŠ¤ë¬´ë”©
    new_topic_label, new_topic_conf = infer_context_topic_label(conversation_memory_std, user_input_std)
    CONTEXT_TOPIC_LABEL, CONTEXT_TOPIC_CONF, _ = smooth_context_topic(
        new_topic_label, new_topic_conf, CONTEXT_TOPIC_LABEL, CONTEXT_TOPIC_CONF,
        min_change_conf=0.60, drift_guard=0.15
    )

    # ì‚¬ì‹¤ ì¶”ì¶œ
    extracted = extract_claims_from_utterance(user_input_std, conversation_memory_std, user_input_raw, nrm_meta)
    if not extracted:
        print("ğŸ’¡ ì¶”ì¶œëœ ì‚¬ì‹¤ ì—†ìŒ.")
        return

    # ê° factì— ë§¥ë½ í† í”½ ë¶€ì—¬
    for nf in extracted:
        nf["topic"] = CONTEXT_TOPIC_LABEL or "ì¼ìƒ"
        nf["topic_confidence"] = float(CONTEXT_TOPIC_CONF)

    # ì €ì¥
    store_extracted_facts(extracted)

    # ê´€ê³„/ì ìˆ˜
    for nf in extracted:
        emb = embedder.encode([nf["claim_text"]])[0]
        olds = [f for f in find_related_old_facts(emb) if f["id"] != nf["id"]]
        d = fact_tracking_agent(nf, olds)
        dval = d.get("decision")
        cb = 1 if dval in ("CONSISTENT","UPDATE","NEW") else 0
        RECENT_CONSISTENCY_BIN.append(cb)
        for f in reversed(fact_memory):
            if f["id"] == nf["id"]:
                f["decision"] = dval
                f["consistency_binary"] = cb
                break
        if dval == "CONTRADICTION":
            memory_score = max(0, memory_score - 15)
        elif dval == "UPDATE":
            memory_score = min(100, memory_score + 5)
        elif dval in ("CONSISTENT","NEW"):
            memory_score = min(100, memory_score + 1)
        print(f"ê²°ì •:{dval}, í˜„ì¬ê¸°ì–µì ìˆ˜:{memory_score}, í† í”½:{CONTEXT_TOPIC_LABEL}({CONTEXT_TOPIC_CONF:.2f})")

# ===================== 10) ë‚ ì§œ/ìŠ¤ì½”ì–´ (KST ì•ˆì •í™”) =====================
try:
    from zoneinfo import ZoneInfo
    _KST = ZoneInfo("Asia/Seoul")
except Exception:
    _KST = None

def _now_kst_dt():
    if CONFIG_TODAY_OVERRIDE:
        try:
            y, m, d = map(int, CONFIG_TODAY_OVERRIDE.split("-"))
            return datetime(y, m, d, 12, 0, 0)  # ì •ì˜¤ ê³ ì •(ê²½ê³„ íšŒí”¼)
        except Exception:
            pass
    try:
        return datetime.now(_KST) if _KST else datetime.now()
    except Exception:
        return datetime.now()

def _today_mmdd_ko():
    now = _now_kst_dt()
    return f"{now.month}ì›” {now.day}ì¼"

def _date_7days_ago_mmdd_ko():
    d = _now_kst_dt() - timedelta(days=7)
    return f"{d.month}ì›” {d.day}ì¼"

def _canonicalize_mmdd(text: str):
    if not text: return None
    s = re.sub(r"\s+", " ", text).strip()
    m = re.search(r'(\d{1,2})\s*ì›”\s*(\d{1,2})\s*ì¼', s)
    if m: return int(m.group(1)), int(m.group(2))
    m = re.search(r'(\d{4})[./-](\d{1,2})[./-](\d{1,2})', s)
    if m: return int(m.group(2)), int(m.group(3))
    m = re.search(r'(\d{1,2})[./-](\d{1,2})', s)
    if m: return int(m.group(1)), int(m.group(2))
    return None

def score_today_date(user_answer_std: str) -> int:
    gold = _canonicalize_mmdd(_today_mmdd_ko())
    pred = _canonicalize_mmdd(user_answer_std or "")
    return 1 if (gold and pred and gold == pred) else 0

def get_today_weather_truth() -> str: return "ë§‘ìŒ"
def normalize_weather_token(s: str) -> str:
    s = (s or "").replace("í•©ë‹ˆë‹¤","").replace("ì—ìš”","").replace("ì˜ˆìš”","").strip()
    if any(x in s for x in ["ë§‘","í•´","ì¨"]): return "ë§‘ìŒ"
    if any(x in s for x in ["í","êµ¬ë¦„"]): return "íë¦¼"
    if "ë¹„" in s: return "ë¹„"
    if "ëˆˆ" in s: return "ëˆˆ"
    if any(x in s for x in ["ë¥","ë¬´ë¥","ë”ì›€","í­ì—¼"]): return "ë”ì›€"
    if any(x in s for x in ["ì¶”","í•œíŒŒ","ìŒ€ìŒ€"]): return "ì¶”ì›€"
    return s

def score_today_weather(user_answer_std: str) -> int:
    gold = normalize_weather_token(get_today_weather_truth())
    pred = normalize_weather_token(user_answer_std)
    return 1 if (gold and pred and gold == pred) else 0

def get_current_location_truth() -> str: return "ì„œìš¸"
def location_match(user_loc: str, truth_loc: str) -> bool:
    return bool(user_loc) and (truth_loc in user_loc or user_loc in truth_loc)
def score_current_location(user_answer_std: str) -> int:
    gold = get_current_location_truth()
    return 1 if location_match(user_answer_std, gold) else 0

def _parse_any_mmdd(text: str):
    return _canonicalize_mmdd(text)

def score_seven_days_ago(user_answer_std: str) -> int:
    gold = _canonicalize_mmdd(_date_7days_ago_mmdd_ko())
    pred = _parse_any_mmdd(user_answer_std or "")
    return 1 if (gold and pred and gold == pred) else 0

def score_yesterday_activity(answer_std: str) -> int:
    return 1 if answer_std and len(answer_std.strip()) >= 2 else 0

# ===================== 11) Attention =====================
def pick_attention_question() -> str:
    return random.choice(["ìµœê·¼ì— ê°€ì¡±ì´ë‚˜ ì¹œêµ¬ë“¤ê³¼ ë¬´ìŠ¨ ëŒ€í™”ë¥¼ í•˜ì…¨ë‚˜ìš”?",
                          "ìš”ì¦˜ ì–´ë–»ê²Œ ì§€ë‚´ì„¸ìš”?"])

def score_attention(answer_std: str) -> int:
    if not answer_std or len(answer_std.strip()) < 3: return 0
    low = ["ëª°ë¼","ëª¨ë¥´ê² ","ì—†ì–´","ê¸€ì„","ëŒ€ì¶©","ì˜ ê¸°ì–µì´","ê¸°ì–µ ì•ˆ","ìƒê° ì•ˆ","ë‚˜ì¤‘ì—","ê·€ì°®"]
    if any(k in answer_std for k in low): return 0
    return 1

# ===================== 12) Diary (ëª…ë ¹ ì „í™˜ + 3ë¬¸ì¥ ìš”ì•½ + ì €ì¥ ê°•í™”) =====================
DIARY_CHECK_KEYS = ["today_date","today_weather","current_location","date_7days_ago","yesterday_activity"]

DIARY_QUESTION_TEMPLATES = [
    "â€˜{t}â€™ í•˜ë©´ ë– ì˜¤ë¥´ëŠ” ì¥ë©´ì´ë‚˜ ëŠë‚Œì´ ìˆìœ¼ì„¸ìš”?",
    "â€˜{t}â€™ì™€ ê´€ë ¨í•´ì„œ ìµœê·¼ì— ìˆì—ˆë˜ ì¼ í•˜ë‚˜ë§Œ ì´ì•¼ê¸°í•´ ì£¼ì‹¤ë˜ìš”?",
    "â€˜{t}â€™ì´(ê°€) ìš”ì¦˜ ì¼ìƒì— ì–´ë–¤ ì˜í–¥ì„ ì£¼ê³  ìˆë‚˜ìš”?",
    "â€˜{t}â€™ê³¼(ì™€) ê´€ë ¨í•´ ê°€ì¥ ê¸°ì–µì— ë‚¨ëŠ” ìˆœê°„ì€ ì–¸ì œì˜€ë‚˜ìš”?",
    "â€˜{t}â€™ì— ëŒ€í•´ ì˜ˆì „ê³¼ ì§€ê¸ˆì„ ë¹„êµí•˜ë©´ ë­ê°€ ë‹¬ë¼ì¡Œë‚˜ìš”?",
    "â€˜{t}â€™ì´(ê°€) ìš”ì¦˜ ë§ˆìŒì´ë‚˜ ê±´ê°•ì— ì–´ë–¤ ë„ì›€(ë˜ëŠ” ì–´ë ¤ì›€)ì„ ì£¼ë‚˜ìš”?",
    "â€˜{t}â€™ì„(ë¥¼) ê°€ì¡±/ì¹œêµ¬ì™€ ì—°ê²°í•´ì„œ ë– ì˜¤ë¥´ëŠ” ì¼ì´ ìˆì„ê¹Œìš”?",
    "â€˜{t}â€™ì„(ë¥¼) ë‹¤ìŒì— í•  ë•Œ ë°”ë¼ëŠ” ì ì´ë‚˜ ê³„íšì´ ìˆë‚˜ìš”?"
]
def _pick_question(t: str, used: set[int]) -> tuple[str,int]:
    cands = [i for i in range(len(DIARY_QUESTION_TEMPLATES)) if i not in used]
    if not cands: cands = list(range(len(DIARY_QUESTION_TEMPLATES)))
    idx = random.choice(cands)
    return DIARY_QUESTION_TEMPLATES[idx].format(t=t), idx

def diary_rag_reminder(topic: str) -> str | None:
    for sess in reversed(diary_memory):
        for m in reversed(sess.get("messages", [])):
            if m.get("topic") == topic and m.get("role") == "user":
                snippet = m.get("content_std","") or m.get("content","")
                if snippet:
                    return f"ì§€ë‚œë²ˆì— '{topic}'ì— ëŒ€í•´ \"{snippet[:40]}...\" ë¼ê³  ë§ì”€í•˜ì…¨ì–´ìš”."
    return None

def pick_diary_topics(k=3) -> list[str]:
    pool = BACKUP_MACRO_TOPICS[:]
    random.shuffle(pool)
    return pool[:k]

def run_diary_checklist_session(sess: dict) -> dict:
    print("\nğŸ“” ì¼ê¸°ì¥ ëª¨ë“œ ì‹œì‘! ë¨¼ì € ë‹¤ì„¯ ê°€ì§€ë¥¼ í™•ì¸í•´ë³¼ê²Œìš”.\n")
    scores = {}

    def ask_and_log(question: str, tag: str):
        sess["messages"].append({"role":"assistant","content": question, "topic":"ì²´í¬ë¦¬ìŠ¤íŠ¸", "ts": time.time()})
        log_event("assistant", content_raw=question, content_std=question, topic="ì²´í¬ë¦¬ìŠ¤íŠ¸")

        a_raw = input(f"ğŸ‘µ ì‚¬ìš©ì(ë‹µë³€) â† {question} ").strip()
        nrm = normalize_user_utterance(a_raw)
        a_std = nrm["standard"]
        ts_now = time.time()
        sess["messages"].append({"role":"user","content_raw": a_raw, "content_std": a_std, "topic":"ì²´í¬ë¦¬ìŠ¤íŠ¸", "ts": ts_now})
        log_event("user", content_raw=a_raw, content_std=a_std, topic="ì²´í¬ë¦¬ìŠ¤íŠ¸", meta={"tag": tag}, ts=ts_now)
        return a_std

    a1_std = ask_and_log("ì˜¤ëŠ˜ì´ ëª‡ì›” ë©°ì¹ ì¼ê¹Œìš”?", "today_date")
    scores["today_date"] = score_today_date(a1_std)

    a2_std = ask_and_log("ì˜¤ëŠ˜ ë‚ ì”¨ëŠ” ì–´ë–¤ê°€ìš”?", "today_weather")
    scores["today_weather"] = score_today_weather(a2_std)

    a3_std = ask_and_log("ì§€ê¸ˆ ì–´ë””ì— ê³„ì‹ ê°€ìš”?", "current_location")
    scores["current_location"] = score_current_location(a3_std)

    a4_std = ask_and_log("ì˜¤ëŠ˜ë¡œë¶€í„° 7ì¼ ì „ì€ ëª‡ì›” ë©°ì¹ ì¼ê¹Œìš”?", "date_7days_ago")
    scores["date_7days_ago"] = score_seven_days_ago(a4_std)

    a5_std = ask_and_log("ì–´ì œ ë­í•˜ì…¨ì–´ìš”?", "yesterday_activity")
    scores["yesterday_activity"] = score_yesterday_activity(a5_std)

    total = sum(scores.get(k,0) for k in DIARY_CHECK_KEYS)
    print(f"\nğŸ“Š ì²´í¬ ê²°ê³¼: {scores} (í•©ê³„ {total}/5)\n")
    return {"scores": scores, "total": total, "asked_at": time.time()}

def _collect_topic_user_texts(sess: dict) -> dict:
    bucket = {t: [] for t in sess.get("topics", [])}
    for m in sess.get("messages", []):
        if m.get("role") == "user":
            t = m.get("topic")
            if t in bucket:
                txt = (m.get("content_std") or "").strip()
                if txt:
                    bucket[t].append(txt)
    return bucket

def _one_sentence_summary(topic: str, texts: list[str]) -> str:
    if not texts:
        return f"â€˜{topic}â€™ì— ëŒ€í•´ì„œëŠ” íŠ¹ë³„íˆ ë‚¨ê¸´ ë‚´ìš©ì´ ì—†ì—ˆì–´ìš”."
    joined = " / ".join(texts[-8:])
    prompt = (
        "ì•„ë˜ í•œêµ­ì–´ ì‚¬ìš©ì ë°œí™”ë¥¼ ë°”íƒ•ìœ¼ë¡œ, **ì •í™•íˆ í•œ ë¬¸ì¥**ìœ¼ë¡œ í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ ì£¼ì„¸ìš”.\n"
        "ìƒˆ ì •ë³´ ì°½ì‘ ê¸ˆì§€, ì¡´ëŒ“ë§, 30~60ì.\n"
        f"[ì£¼ì œ] {topic}\n[ë°œí™”ë“¤]\n{joined}\n\n[ì¶œë ¥] í•œ ë¬¸ì¥:"
    )
    sent = ask_gpt(prompt, model="gpt-4o-mini", temperature=0.2, max_tokens=80,
                   response_format={"type":"text"})
    return (sent or "").strip() or f"â€˜{topic}â€™ì— ëŒ€í•´ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•  ë‚´ìš©ì´ ì ì—ˆìŠµë‹ˆë‹¤."

def summarize_diary_session(sess: dict) -> list[dict]:
    topics = sess.get("topics", [])
    buckets = _collect_topic_user_texts(sess)
    summaries = []
    print("ğŸ“ ì˜¤ëŠ˜ì˜ ì¼ê¸°ì¥ ìš”ì•½ (í† í”½ë‹¹ 1ë¬¸ì¥)")
    for t in topics:
        sent = _one_sentence_summary(t, buckets.get(t, []))
        print(f"- {sent}")
        summaries.append({"topic": t, "summary": sent})
    sess["diary_summaries"] = summaries
    return summaries

def run_diary_topic_conversations(sess: dict, k_topics=3):
    topics = pick_diary_topics(k_topics)
    sess["topics"] = topics
    print(f"ğŸ§© ì˜¤ëŠ˜ì˜ ëŒ€í™” ì£¼ì œ: {', '.join(topics)}\n")
    remaining = topics[:]
    used_question_idx_map = {t:set() for t in topics}

    while remaining:
        t = remaining[0]
        print(f"â€” ì£¼ì œ [{t}] â€”")
        memo = diary_rag_reminder(t)
        if memo:
            print(f"ğŸ“ ë¦¬ë§ˆì¸ë“œ: {memo}")
            log_event("assistant", content_raw=memo, content_std=memo, topic=t, meta={"type":"reminder"})

        q, qidx = _pick_question(t, used_question_idx_map[t])
        used_question_idx_map[t].add(qidx)

        ts_q = time.time()
        sess["messages"].append({"role":"assistant","content": q, "topic": t, "ts": ts_q})
        log_event("assistant", content_raw=q, content_std=q, topic=t, ts=ts_q, meta={"qidx": qidx})

        user_a_raw = input(f"ğŸ‘µ ì‚¬ìš©ì(ë‹µë³€) â† {q} ").strip()
        nrm = normalize_user_utterance(user_a_raw)
        a_std = nrm["standard"]

        ts_a = time.time()
        sess["messages"].append({"role":"user","content_raw": user_a_raw, "content_std": a_std, "topic": t, "ts": ts_a})
        log_event("user", content_raw=user_a_raw, content_std=a_std, topic=t, ts=ts_a)

        if any(w in a_std for w in DIARY_STOP_WORDS):
            msg = "ğŸ“ ì•Œê² ìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ ì¼ê¸°ì¥ì€ ì—¬ê¸°ê¹Œì§€ë¡œ ë§ˆì¹ ê²Œìš”.\n"
            print(msg)
            log_event("assistant", content_raw=msg, content_std=msg, topic=t, meta={"type":"diary_end"})
            sess["__force_end__"] = True
            break

        if any(w in a_std for w in DIARY_NEXT_WORDS) and len(remaining) > 1:
            next_topic = remaining[1]
            transition = f"ì¢‹ì•„ìš”. ê·¸ëŸ¼ ë‹¤ìŒìœ¼ë¡œ â€˜{next_topic}â€™ ì´ì•¼ê¸°ë„ í•´ë³¼ê²Œìš”."
            print(f"ğŸ§  ì‹œìŠ¤í…œ: {transition}\n")
            sess["messages"].append({"role":"assistant","content": transition, "topic": t, "ts": time.time()})
            log_event("assistant", content_raw=transition, content_std=transition, topic=t, meta={"type":"topic_switch","next":next_topic})
            remaining.pop(0)
            continue

        global FINETUNED_EMPATHY_MODEL
        if FINETUNED_EMPATHY_MODEL is None:
            FINETUNED_EMPATHY_MODEL = resolve_finetuned_model(EMPATHY_FT_JOB_ID)
        prompt = (
            f"{few_shot_empathy}\n\nì‚¬ìš©ì ë°œí™”: \"{a_std}\"\n"
            f"ì´ì „ ëŒ€í™” íë¦„: {' '.join(conversation_memory_std[-3:])}\n"
            f"ê³µê° 1ë¬¸ì¥ + ìì—°ìŠ¤ëŸ¬ìš´ ì¶”ê°€ ì§ˆë¬¸ 1ë¬¸ì¥ ë§Œë“¤ì–´ì£¼ì„¸ìš”.\nì‘ë‹µ:"
        )
        follow = ask_gpt(prompt, model=FINETUNED_EMPATHY_MODEL or "gpt-4o-mini",
                         temperature=0.6, max_tokens=180, response_format={"type":"text"})
        print(f"ğŸ§  ì‹œìŠ¤í…œ: {follow}\n")
        sess["messages"].append({"role":"assistant","content": follow, "topic": t, "ts": time.time()})
        log_event("assistant", content_raw=follow, content_std=follow, topic=t, meta={"type":"followup"})

        if len(used_question_idx_map[t]) >= len(DIARY_QUESTION_TEMPLATES) and len(remaining) > 1:
            next_topic = remaining[1]
            transition = f"ê·¸ëŸ¼ â€˜{next_topic}â€™ ì´ì•¼ê¸°ë„ ì´ì–´ì„œ ë‚˜ëˆ ë³¼ê¹Œìš”?"
            print(f"ğŸ§  ì‹œìŠ¤í…œ: {transition}\n")
            sess["messages"].append({"role":"assistant","content": transition, "topic": t, "ts": time.time()})
            log_event("assistant", content_raw=transition, content_std=transition, topic=t, meta={"type":"topic_switch","next":next_topic})
            remaining.pop(0)

def start_diary_mode():
    global diary_id_counter, DIARY_MODE
    DIARY_MODE = True
    sess = {
        "diary_id": f"diary_{diary_id_counter}",
        "started_at": time.time(),
        "scores": {},
        "score_total": 0,
        "messages": [],
        "topics": [],
        "diary_summaries": []
    }
    check_res = run_diary_checklist_session(sess)
    sess["scores"] = check_res["scores"]; sess["score_total"] = check_res["total"]
    run_diary_topic_conversations(sess, k_topics=3)
    summarize_diary_session(sess)
    sess["ended_at"] = time.time()
    diary_memory.append(sess)
    diary_id_counter += 1
    DIARY_MODE = False
    print(f"âœ… ì¼ê¸°ì¥ ì„¸ì…˜ ì €ì¥ ì™„ë£Œ: {sess['diary_id']} (ì²´í¬ {sess['score_total']}/5, ë©”ì‹œì§€ {len(sess['messages'])}ê°œ)\n")

# ===================== 13) ì¼ë°˜ ëŒ€í™” =====================
def generate_question(user_input_std: str):
    global FINETUNED_EMPATHY_MODEL
    if FINETUNED_EMPATHY_MODEL is None:
        FINETUNED_EMPATHY_MODEL = resolve_finetuned_model(EMPATHY_FT_JOB_ID)
    prompt = (
        f"{few_shot_empathy}\n\nì‚¬ìš©ì ë°œí™”: \"{user_input_std}\"\n"
        f"ì´ì „ ëŒ€í™” íë¦„: {' '.join(conversation_memory_std[-3:])}\n"
        f"ê³µê° 1ë¬¸ì¥ + ìì—°ìŠ¤ëŸ¬ìš´ ì¼ìƒ ì§ˆë¬¸ 1ë¬¸ì¥ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.\nì‘ë‹µ:"
    )
    return ask_gpt(prompt, model=FINETUNED_EMPATHY_MODEL or "gpt-4o-mini",
                   temperature=0.6, max_tokens=180, response_format={"type":"text"})

# ===================== 14) CSV Export =====================
def export_fact_memory_csv(path: str = "fact_memory.csv") -> str:
    if not fact_memory:
        print("fact_memoryê°€ ë¹„ì–´ ìˆì–´ìš”. íŒŒì¼ì„ ë§Œë“¤ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return ""
    header = set()
    for f in fact_memory:
        header.update(f.keys())
    header = list(header)
    preferred = ["id","claim_text","summary","entities","type",
                 "topic","topic_confidence",
                 "time_reference","relative_offset_days","timestamp",
                 "original_utterance_raw","original_utterance_std",
                 "decision","consistency_binary"]
    ordered = [h for h in preferred if h in header] + [h for h in header if h not in preferred]
    p = Path(path)
    with p.open("w", newline="", encoding="utf-8-sig") as f:
        writer = csv.DictWriter(f, fieldnames=ordered)
        writer.writeheader()
        for row in fact_memory:
            r = dict(row)
            if isinstance(r.get("entities"), list):
                r["entities"] = ", ".join(map(str, r["entities"]))
            if r.get("timestamp"):
                r["timestamp"] = _ts(r["timestamp"])
            writer.writerow({k: r.get(k, "") for k in ordered})
    print(f"âœ… fact_memoryë¥¼ CSVë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤: {p.resolve()}")
    return str(p.resolve())

def export_diary_memory_csv(sessions_csv_path: str, messages_csv_path: str):
    """
    diary_memory(list of sess dict)ë¥¼ ë‘ ê°œ CSVë¡œ ì €ì¥:
      1) sessions_csv_path: ì„¸ì…˜ ìš”ì•½ (5ë¬¸í•­ ì ìˆ˜ 0/1 + í•©ê³„ + í† í”½ + ìš”ì•½ë¬¸)
      2) messages_csv_path: ëª¨ë“  ë©”ì‹œì§€ (role, topic, content_raw, content_std, ts, meta)
    """
    import csv, json

    # ---- 1) ì„¸ì…˜ CSV ----
    session_cols = [
        "id", "started_at",
        "score_today_date", "score_today_weather", "score_current_location",
        "score_date_7days_ago", "score_yesterday_activity",
        "score_total",
        "topics",
        "summaries_text",
    ]
    # âœ… ì—‘ì…€ í•œê¸€ í˜¸í™˜: utf-8-sig
    with open(sessions_csv_path, "w", newline="", encoding="utf-8-sig") as sf:
        w = csv.DictWriter(sf, fieldnames=session_cols)
        w.writeheader()
        for sess in diary_memory:
            sid = sess.get("id")
            started_at = sess.get("started_at")

            sc = sess.get("scores", {}) or {}
            s_today   = int(sc.get("today_date", 0) or 0)
            s_weather = int(sc.get("today_weather", 0) or 0)
            s_loc     = int(sc.get("current_location", 0) or 0)
            s_7ago    = int(sc.get("date_7days_ago", 0) or 0)
            s_yest    = int(sc.get("yesterday_activity", 0) or 0)
            s_total   = s_today + s_weather + s_loc + s_7ago + s_yest

            topics = sess.get("topics", []) or []
            sums   = sess.get("diary_summaries", []) or []
            summaries_text = " | ".join(
                f"[{x.get('topic','')}] {x.get('summary','')}" for x in sums
            )

            w.writerow({
                "id": sid,
                "started_at": started_at,
                "score_today_date": s_today,
                "score_today_weather": s_weather,
                "score_current_location": s_loc,
                "score_date_7days_ago": s_7ago,
                "score_yesterday_activity": s_yest,
                "score_total": s_total,
                "topics": ", ".join(topics),
                "summaries_text": summaries_text,
            })

    # ---- 2) ë©”ì‹œì§€ CSV ----
    msg_cols = ["session_id", "ts", "role", "topic", "content_raw", "content_std", "meta_json"]
    # âœ… ì—‘ì…€ í•œê¸€ í˜¸í™˜: utf-8-sig
    with open(messages_csv_path, "w", newline="", encoding="utf-8-sig") as mf:
        w = csv.DictWriter(mf, fieldnames=msg_cols)
        w.writeheader()
        for sess in diary_memory:
            sid = sess.get("id")
            msgs = sess.get("messages", []) or []
            for m in msgs:
                raw = m.get("content_raw")
                std = m.get("content_std")
                base = m.get("content")  # assistant ì§ˆë¬¸ë§Œ contentì— ìˆì„ ìˆ˜ë„ ìˆìŒ
                if raw is None and base is not None:
                    raw = base
                if std is None and base is not None:
                    std = base

                w.writerow({
                    "session_id": sid,
                    "ts": m.get("ts"),
                    "role": m.get("role"),
                    "topic": m.get("topic"),
                    "content_raw": raw or "",
                    "content_std": std or "",
                    "meta_json": json.dumps(m.get("meta", {}), ensure_ascii=False),
                })

    return sessions_csv_path, messages_csv_path



# ===================== 15) Main Chat Loop =====================
def chat_loop():
    print("\nğŸ§  ì¹˜ë§¤ ëŒ€í™” ì‹œìŠ¤í…œ ì‹œì‘ (ì¢…ë£Œ: 'ê·¸ë§Œ') â€” ì¼ê¸°ì¥ ì €ì¥/ë‚ ì§œ ì±„ì  FIX ë°˜ì˜")
    print("ì²˜ìŒì— ì£¼ì˜ë ¥(Attention) ì§ˆë¬¸ í•˜ë‚˜ë¥¼ ë“œë¦´ê²Œìš”.\n")

    att_q = pick_attention_question()
    log_event("assistant", content_raw=att_q, content_std=att_q, topic="ì£¼ì˜ë ¥")

    att_ans_raw = input(f"ğŸ‘µ ì‚¬ìš©ì: {att_q} ").strip()
    nrm = normalize_user_utterance(att_ans_raw)
    att_ans_std = nrm["standard"]
    log_event("user", content_raw=att_ans_raw, content_std=att_ans_std, topic="ì£¼ì˜ë ¥")

    att_score = score_attention(att_ans_std)
    print(f"ğŸ“Š Attention ì ìˆ˜: {att_score}")

    att_sess = {
        "diary_id": f"attention_{int(time.time())}",
        "started_at": time.time(),
        "attention_question": att_q,
        "attention_answer_raw": att_ans_raw,
        "attention_answer_std": att_ans_std,
        "attention": att_score,
        "messages": []
    }
    diary_memory.append(att_sess)

    while True:
        user_input_raw = input("ğŸ‘µ ì‚¬ìš©ì: ").strip()
        if user_input_raw.lower() == "ê·¸ë§Œ":
            print("\nì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ì•ˆë…•íˆ ê³„ì„¸ìš”!")
            log_event("user", content_raw="ê·¸ë§Œ", content_std="ê·¸ë§Œ", topic="")
            break
        if not user_input_raw:
            continue

        nrm = normalize_user_utterance(user_input_raw)
        user_input_std = nrm["standard"]

        conversation_memory_raw.append(user_input_raw)
        conversation_memory_std.append(user_input_std)

        log_event("user", content_raw=user_input_raw, content_std=user_input_std, topic=CONTEXT_TOPIC_LABEL or "")

        if "ì¼ê¸°" in user_input_std or "ì¼ê¸°" in user_input_raw:
            start_diary_mode()
            continue

        check_memory_consistency(user_input_std, user_input_raw, nrm)

        reply = generate_question(user_input_std)
        print(f"\nğŸ§  ì‹œìŠ¤í…œ: {reply}\n")
        log_event("assistant", content_raw=reply, content_std=reply, topic=CONTEXT_TOPIC_LABEL or "")
        time.sleep(0.3)